{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MyHW1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1xLZ5XGSWps286aXr2R8P7esPXT0ftYsW",
      "authorship_tag": "ABX9TyNOOTpGH2ZI72o9zF0wU9iX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yanxiaoqi932/Machine-Learning/blob/main/MyHW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7YQ5S5lpuB-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Djkn-9nXpw3E"
      },
      "source": [
        "## Machine learning homework 1:\n",
        "##  regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fqd8Bo8VStJ"
      },
      "source": [
        "# 训练集文件和测试集文件下载"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYnm4f6Ap2ea",
        "outputId": "6edaf3d0-241e-4a8c-c65a-79190e1b77e6"
      },
      "source": [
        "#下载文件\n",
        "!gdown --id '19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF' --output covid.train.csv\n",
        "!gdown --id '1CE240jLm2npU-tdz81-oVKEF3T2yfT1O' --output covid.test.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF\n",
            "To: /content/covid.train.csv\n",
            "100% 2.00M/2.00M [00:00<00:00, 63.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CE240jLm2npU-tdz81-oVKEF3T2yfT1O\n",
            "To: /content/covid.test.csv\n",
            "100% 651k/651k [00:00<00:00, 42.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkG8rF8VtEM9"
      },
      "source": [
        "#定义文件路径\n",
        "tr_path = '/content/covid.train.csv'\n",
        "tt_path = '/content/covid.test.csv'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13p0PnSbVflA"
      },
      "source": [
        "# 导入有关的包，并定义随机数种子"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOxKM-1ItQ6t"
      },
      "source": [
        "'''导入有关的包'''\n",
        "#Pytorch系列\n",
        "import torch\n",
        "import torch.nn as nn   #神经网络包\n",
        "from torch.utils.data import Dataset,DataLoader   #数据集和数据加载库\n",
        "from torch.optim.lr_scheduler import StepLR     #修改学习率所用\n",
        "\n",
        "#传统数据处理库\n",
        "import numpy as np\n",
        "import csv\n",
        "import os   #路径操作和进程管理等\n",
        "\n",
        "#画图库\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "#设置随机种子（seed）\n",
        "'''如有不懂，可以查询Pytorch文档网址:\n",
        "  https://pytorch.org/docs/stable/backends.html\n",
        "'''\n",
        "torch.backends.cudnn.deterministic = True   #顾名思义，将这个 flag 置为True的话，每次返回的卷积算法将是确定的，即默认算法。\n",
        "                        #如果配合上设置 Torch 的随机种子为固定值的话，应该可以保证每次运行网络的时候相同输入的输出是固定的\n",
        "torch.backends.cudnn.benchmark = False   #如果为 True，则导致 cuDNN 对多个卷积算法进行基准测试并选择最快的。 \n",
        "myseed = 42069         #随机数种子选择对结果是有一定影响的，可见https://blog.csdn.net/weixin_43991828/article/details/114378660\n",
        "torch.manual_seed(myseed)   #如果是cpu，则在此设置种子\n",
        "torch.cuda.manual_seed(myseed)     #如果是gpu，则在此设置种子\n",
        "if torch.cuda.is_available:      #如果有多个gpu，则全部设置该种子\n",
        "  torch.cuda.manual_seed_all(myseed)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy4A1_3uVu3g"
      },
      "source": [
        "# 数据集的建立和处理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m6oRXejVtmJ"
      },
      "source": [
        "class COVID19Dataset(Dataset):\n",
        "  '''数据集下载和处理'''\n",
        "  def __init__(self,path,mode='train',target_only=False): #target_only用于对feature进行选择，默认全部feature都选择,如果是True则选择自定义的部分\n",
        "    self.mode = mode      #训练/验证/测试\n",
        "    with open(path,'r') as fp:\n",
        "      data = list(csv.reader(fp))\n",
        "      data = np.array(data[1:])[:,1:].astype(float) #去除行头和列头，得到矩阵\n",
        "\n",
        "    #关于features的选取\n",
        "    if not target_only:   #target_only为false\n",
        "      features = list(range(93)) #40 states + day 1(18) + day2(18) + day3(17)，共93个特征\n",
        "    else:\n",
        "      # features = list(range(40)) + [57,75]\n",
        "      features = [75, 57, 42, 60, 78, 43, 61, 79, 40, 58, 76, 41, 59, 77]\n",
        "    \n",
        "    alldata = torch.FloatTensor(data[:,features])    #特征数据\n",
        "    alltarget = torch.FloatTensor(data[:,-1])    #训练目标\n",
        "\n",
        "    #对于测试集的数据处理\n",
        "    if mode == 'test':\n",
        "      self.data = torch.FloatTensor(alldata)  #取出所有特征数据，测试集没有目标结果数据\n",
        "    \n",
        "    #对于训练集的数据处理\n",
        "    elif mode == 'train':\n",
        "      indices = [i for i in range(len(alldata)) if i%10!=0]   #每10个数据中取出9个作为训练集\n",
        "      self.data = torch.FloatTensor(alldata[indices])\n",
        "      self.target = torch.FloatTensor(alltarget[indices])\n",
        "      #存储归一化后的训练集数据为csv文件，方便检查问题\n",
        "      with open('Ztrain_data.csv','w') as fp:\n",
        "        writer = csv.writer(fp)\n",
        "        z_score_tensor = self.data;\n",
        "        z_score_numpy = z_score_tensor.numpy()\n",
        "        for i in range(z_score_numpy.shape[0]):\n",
        "          writer.writerow(z_score_numpy[i,:])\n",
        "\n",
        "    #对于验证集的数据处理\n",
        "    else:\n",
        "      print('dev')\n",
        "      indices = [i for i in range(len(alldata)) if i%10==0]   #每10个数据中取出1个作为验证集\n",
        "      self.data = torch.FloatTensor(alldata[indices])\n",
        "      self.target = torch.FloatTensor(alltarget[indices])\n",
        "    \n",
        "    #打印完成语句\n",
        "    self.dim = self.data.shape[1]\n",
        "    print('Finished reading the {} set of COVID dataset ({} samples found,each dim = {})'.format(mode,len(self.data),self.dim))\n",
        "    \n",
        "    #对测试集、训练集、验证集的数据进行标准化处理\n",
        "    #Z-score标准化数据（day123的features数据）\n",
        "    # self.data[:,40:] = (self.data[:,40:] - self.data[:,40:].mean(dim=0,keepdim=True)) / (self.data[:,40:].std(dim=0,keepdim=True))\n",
        "    self.data[:,:] = (self.data[:,:] - self.data[:,:].mean(dim=0,keepdim=True)) / (self.data[:,:].std(dim=0,keepdim=True))\n",
        "  #返回一个batch\n",
        "  def __getitem__(self,index):\n",
        "    if self.mode in ['train','dev']:\n",
        "      return self.data[index],self.target[index]\n",
        "    else:\n",
        "      return self.data[index]\n",
        "  \n",
        "  #返回数据的长度\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9dIY4t42x6y"
      },
      "source": [
        "'''Dataloader数据加载器，Dataset创建数据集，DataLoader做进一步处理，最终建立并返回一个成型的数据集'''\n",
        "def prep_dataloader(path,mode,batch_size,n_jobs=0,target_only=False):\n",
        "  dataset = COVID19Dataset(path,mode=mode,target_only=target_only)  #构造一个数据集\n",
        "  dataloader = DataLoader(dataset,batch_size,shuffle=(mode=='train'),drop_last=False,  \n",
        "                          num_workers=n_jobs,pin_memory=True)\n",
        "  #batch_size代表每批要加载的数据数；\n",
        "  #shuffle为true则在每一个epoch会对数据洗牌；\n",
        "  #drop_out为True时，如果数据集大小不能被批处理大小整除，则设置为删除最后一个不完整的批处理，否则保留size较小的最后一批；\n",
        "  #num_workers代表数据加载时的子进程数；\n",
        "  #pin_memory为True时，数据加载器将在返回之前将张量复制到 CUDA 固定内存中\n",
        "  return dataloader"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFvBnmewuo1H"
      },
      "source": [
        "# 建立DNN深度神经网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-HsNQVXwjw9"
      },
      "source": [
        "'''创建一个神经网络，并且定义其中的输入输出维度、损失函数等'''\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self,input_dim):\n",
        "    super(NeuralNet,self).__init__();\n",
        "\n",
        "    #定义网络结构和激活函数\n",
        "    self.net = nn.Sequential(\n",
        "      # nn.Linear(input_dim,64),\n",
        "      # nn.ReLU(),\n",
        "      # nn.Linear(64,1),\n",
        "\n",
        "      nn.Linear(input_dim, 64),\n",
        "      nn.BatchNorm1d(64),\n",
        "      nn.Dropout(p=0.2),\n",
        "      nn.LeakyReLU(),\n",
        "      nn.Linear(64,1)\n",
        "    )\n",
        "\n",
        "    #定义损失函数\n",
        "    self.criterion = nn.MSELoss(reduction='mean')  #损失函数为L2范式，即均方差形式\n",
        "  \n",
        "  def forward(self,batch_size):\n",
        "    return self.net(batch_size).squeeze(1)  #定义模型的batch_size,并且将它降一个维度\n",
        "\n",
        "  def cal_loss(self,pred,target):   #计算模型预测值与验证集真实结果的方差\n",
        "    regularization_loss = 0\n",
        "    for param in model.parameters():\n",
        "      regularization_loss += torch.sum(param ** 2)\n",
        "      # TODO: you may implement L1/L2 regularization here\n",
        "    return self.criterion(pred, target) + 0.00095 * regularization_loss  #加入正则项\n",
        "    '''\n",
        "    个人认为这里的加入正则项，是模型的参数越大，那么overfitting越严重，就应当引入正则项来抑制模型参数过大；\n",
        "    举例如下：\n",
        "      Y = w0 *X0 + w1*X1 + w2*X2 + w3*X3 + … + wd*Xd\n",
        "      如果w2非常大比如106，那么如果X2加一个噪声变为X2 + △, 那么w2*(X2 + △) = W2 * X2 + W2△ \n",
        "      由于W2越大，那么W2△就很大，相当于放大了噪声的影响，模型的鲁棒性就下降，因此会导致模型泛化能力变弱，\n",
        "      因此加入正则惩罚（减小）了w的值，减少模型过拟合，提高了模型的泛化能力。\n",
        "    '''"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goj0DZ73223O"
      },
      "source": [
        "# 训练过程定义"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-EwShIj2-h7"
      },
      "source": [
        "'''对训练集进行训练，并记录loss，生成模型'''\n",
        "def train(tr_set,dv_set,model,config,device):   #训练集的运行（注意，训练集跑一次，验证集也要跑一次）\n",
        "  \n",
        "  #优化器设置\n",
        "  optimizer = getattr(torch.optim,config['optimizer'])(model.parameters(),**config['optim_hparas']) #getattr()函数用于返回一个对象属性值\n",
        "  #也可以直接在这里设置：optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "  min_mse = 1000  #初始化损失为1000\n",
        "  loss_record = {'train':[],'dev':[]}   #loss在训练集和验证集上的大小\n",
        "\n",
        "  early_stop_cnt = 0    #保持最小loss没有被刷新的最长epoches量\n",
        "  epoch = 0   #epoch量\n",
        "  n_epoches = config['n_epoches']   #最大训练epoch量，由字典config存储\n",
        "\n",
        "  #开始训练\n",
        "  while epoch<n_epoches:\n",
        "    #首先在模型集上训练模型，并得到训练集的loss\n",
        "    model.train()   #将模型设置为训练模式\n",
        "    tr_loss = 0   #记录训练集的测试精度\n",
        "    for x,y in tr_set:  #x为训练集特征数据，y为训练集目标数据（见于COVID19Dataset）\n",
        "      '''接下来是基本的迭代步骤'''\n",
        "      optimizer.zero_grad()\n",
        "      x,y = x.to(device),y.to(device)   #将数据x，y存入硬件内存中\n",
        "      pred = model(x)   #模型得到预测值\n",
        "      mse_loss = model.cal_loss(pred,y)   #计算预测值与训练集目标值的差距\n",
        "      mse_loss.backward()   #反向传播算法，修改w，b参数值和学习率\n",
        "      optimizer.step()    #参数更新，得到新模型\n",
        "      tr_loss += mse_loss.detach().cpu().item() * len(x)\n",
        "      tr_loss /= len(tr_set.dataset)\n",
        "      loss_record['train'].append(tr_loss)   #把mse_loss中的数值取出\n",
        "      #对训练后的值需要进行一些转换，包括detach(),cpu(),item(),numpy()等函数，\n",
        "      #detach()阻断反向传播，返回tensor\n",
        "      #cpu()是将cuda上的值存储到cpu上，返回tensor\n",
        "      #item()返回的是tensor中的值，且只能返回单个值（标量），不能返回向量，一般用于返回loss\n",
        "      #numpy()将tensor转换为numpy\n",
        "      #具体参考文章：https://blog.csdn.net/weixin_43289424/article/details/105803097\n",
        "\n",
        "    #接着将模型放在验证集上测验\n",
        "    dev_mse = dev(dv_set,model,device)  #计算模型在验证集上的损失\n",
        "    if dev_mse < min_mse:\n",
        "      min_mse = dev_mse\n",
        "      print('Saving model (epoch = {:4d},loss = {:.4f})'.format(epoch+1,min_mse))\n",
        "      torch.save(model.state_dict(),config['save_path'])  #将模型保存\n",
        "      early_stop_cnt = 0\n",
        "    else:\n",
        "      early_stop_cnt += 1\n",
        "    \n",
        "    epoch += 1\n",
        "    loss_record['dev'].append(dev_mse)\n",
        "    \n",
        "    if early_stop_cnt > config['early_stop']:   #如果验证集上最小损失长期未被刷新，那么将结束训练\n",
        "      print('training set accuracy:{}\\ndev set accuracy:{}'.format(tr_loss,min_mse))\n",
        "      break\n",
        "  print('Finished training after {} epoches'.format(epoch))\n",
        "  return min_mse,loss_record\n",
        "\n",
        "  \n",
        "'''用于计算训练过程中模型在验证集上得到的loss'''\n",
        "def dev(dv_set,model,device):\n",
        "  model.eval()    #将模型训练为验证模式\n",
        "  total_loss = 0\n",
        "  for x,y in dv_set:  #x为验证集特征数据，y为验证集目标数据\n",
        "    x,y = x.to(device),y.to(device)\n",
        "    with torch.no_grad():   #禁止求导\n",
        "      pred = model(x)\n",
        "      mse_loss = model.cal_loss(pred,y)\n",
        "    total_loss += mse_loss.detach().cpu().item() * len(x) #累加损失值，len()返回矩阵x的第一维，也就是行数\n",
        "    total_loss = total_loss / len(dv_set.dataset) #计算损失平均值\n",
        "  return total_loss\n",
        "\n",
        "'''用于在测试集中生成预测结果'''\n",
        "def test(tt_set,model,device):\n",
        "  model.eval()\n",
        "  preds = []\n",
        "  for x in tt_set:\n",
        "    x = x.to(device)\n",
        "    with torch.no_grad():\n",
        "      pred = model(x)\n",
        "      preds.append(pred.detach().cpu())\n",
        "  preds = torch.cat(preds,dim=0).numpy()\n",
        "  return preds"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd4eBQON-LYj"
      },
      "source": [
        "# 设置自定义参数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQgOzA08YnTc"
      },
      "source": [
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "else:\n",
        "  device = 'cpu'\n",
        "\n",
        "os.makedirs('models',exist_ok=True)    #创建model文件夹\n",
        "target_only = True     #选择自定义的特征\n",
        "\n",
        "#对参数字典config的定义\n",
        "config = {\n",
        "    'n_epoches':10000,    #最大迭代次数\n",
        "    'batch_size':270,    #每个训练batch的大小\n",
        "    'optimizer':'SGD',    #优化器选择Adam，Adam属于自适应优化算法，不需要定义学习率等等\n",
        "    'optim_hparas':{\n",
        "      'lr':0.001    #优化器参数定义，学习率为0.0001\n",
        "      # 'momentum':0.9\n",
        "    },\n",
        "    'early_stop':500,    #验证集最小损失未被刷新迭代长度上限(超过上限则停止训练)\n",
        "    'save_path':'models/model.pth'  #模型存储路径\n",
        "}"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8c-uBf8c3-C"
      },
      "source": [
        "# 加载数据和模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoAwhAsWc-FK",
        "outputId": "2d55ba51-a206-4a67-8705-52ff85a91111"
      },
      "source": [
        "tr_set = prep_dataloader(tr_path,'train',config['batch_size'],target_only=target_only)\n",
        "dv_set = prep_dataloader(tr_path,'dev',config['batch_size'],target_only=target_only)\n",
        "tt_set = prep_dataloader(tt_path,'test',config['batch_size'],target_only=target_only)\n",
        "\n",
        "#建立model实例\n",
        "model = NeuralNet(tr_set.dataset.dim).to(device)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished reading the train set of COVID dataset (2430 samples found,each dim = 14)\n",
            "dev\n",
            "Finished reading the dev set of COVID dataset (270 samples found,each dim = 14)\n",
            "Finished reading the test set of COVID dataset (893 samples found,each dim = 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxMcq3aZDZRR"
      },
      "source": [
        "# 开始训练！"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR65U7QODfWL",
        "outputId": "7da4d386-d7a4-4ef5-f733-2d2dc5840133"
      },
      "source": [
        "model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)  #model_loss_record记录了在训练集和验证集上跑出的结果"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model (epoch =    1,loss = 244.6180)\n",
            "Saving model (epoch =    2,loss = 160.0492)\n",
            "Saving model (epoch =    3,loss = 107.9918)\n",
            "Saving model (epoch =    4,loss = 73.5178)\n",
            "Saving model (epoch =    5,loss = 49.2968)\n",
            "Saving model (epoch =    6,loss = 36.2510)\n",
            "Saving model (epoch =    7,loss = 29.3276)\n",
            "Saving model (epoch =    8,loss = 25.7496)\n",
            "Saving model (epoch =    9,loss = 24.1248)\n",
            "Saving model (epoch =   10,loss = 22.2060)\n",
            "Saving model (epoch =   13,loss = 21.6609)\n",
            "Saving model (epoch =   14,loss = 18.8038)\n",
            "Saving model (epoch =   16,loss = 17.9706)\n",
            "Saving model (epoch =   18,loss = 17.0053)\n",
            "Saving model (epoch =   19,loss = 16.5933)\n",
            "Saving model (epoch =   21,loss = 16.0806)\n",
            "Saving model (epoch =   22,loss = 16.0140)\n",
            "Saving model (epoch =   23,loss = 14.9322)\n",
            "Saving model (epoch =   27,loss = 14.4856)\n",
            "Saving model (epoch =   31,loss = 12.9822)\n",
            "Saving model (epoch =   34,loss = 12.0721)\n",
            "Saving model (epoch =   36,loss = 11.6246)\n",
            "Saving model (epoch =   37,loss = 11.0085)\n",
            "Saving model (epoch =   40,loss = 10.5958)\n",
            "Saving model (epoch =   44,loss = 9.9923)\n",
            "Saving model (epoch =   46,loss = 9.6326)\n",
            "Saving model (epoch =   47,loss = 9.1076)\n",
            "Saving model (epoch =   49,loss = 8.7201)\n",
            "Saving model (epoch =   54,loss = 8.5687)\n",
            "Saving model (epoch =   56,loss = 8.3241)\n",
            "Saving model (epoch =   59,loss = 7.3024)\n",
            "Saving model (epoch =   60,loss = 7.2423)\n",
            "Saving model (epoch =   61,loss = 7.0766)\n",
            "Saving model (epoch =   65,loss = 7.0369)\n",
            "Saving model (epoch =   66,loss = 6.4959)\n",
            "Saving model (epoch =   69,loss = 6.0832)\n",
            "Saving model (epoch =   72,loss = 5.8372)\n",
            "Saving model (epoch =   73,loss = 5.7006)\n",
            "Saving model (epoch =   74,loss = 5.5864)\n",
            "Saving model (epoch =   79,loss = 5.4359)\n",
            "Saving model (epoch =   81,loss = 5.1684)\n",
            "Saving model (epoch =   83,loss = 4.8422)\n",
            "Saving model (epoch =   87,loss = 4.7250)\n",
            "Saving model (epoch =   90,loss = 4.6838)\n",
            "Saving model (epoch =   91,loss = 4.4362)\n",
            "Saving model (epoch =   94,loss = 4.4042)\n",
            "Saving model (epoch =   98,loss = 3.8523)\n",
            "Saving model (epoch =  101,loss = 3.7850)\n",
            "Saving model (epoch =  103,loss = 3.6443)\n",
            "Saving model (epoch =  105,loss = 3.5898)\n",
            "Saving model (epoch =  106,loss = 3.5548)\n",
            "Saving model (epoch =  116,loss = 3.3623)\n",
            "Saving model (epoch =  117,loss = 3.0950)\n",
            "Saving model (epoch =  118,loss = 2.9867)\n",
            "Saving model (epoch =  120,loss = 2.9820)\n",
            "Saving model (epoch =  121,loss = 2.9481)\n",
            "Saving model (epoch =  122,loss = 2.8985)\n",
            "Saving model (epoch =  123,loss = 2.8136)\n",
            "Saving model (epoch =  127,loss = 2.7672)\n",
            "Saving model (epoch =  128,loss = 2.6891)\n",
            "Saving model (epoch =  129,loss = 2.6086)\n",
            "Saving model (epoch =  131,loss = 2.5542)\n",
            "Saving model (epoch =  132,loss = 2.5116)\n",
            "Saving model (epoch =  133,loss = 2.4700)\n",
            "Saving model (epoch =  136,loss = 2.4119)\n",
            "Saving model (epoch =  141,loss = 2.2805)\n",
            "Saving model (epoch =  147,loss = 2.1842)\n",
            "Saving model (epoch =  152,loss = 2.1298)\n",
            "Saving model (epoch =  153,loss = 2.1066)\n",
            "Saving model (epoch =  154,loss = 2.0957)\n",
            "Saving model (epoch =  155,loss = 2.0650)\n",
            "Saving model (epoch =  162,loss = 1.9389)\n",
            "Saving model (epoch =  166,loss = 1.9016)\n",
            "Saving model (epoch =  170,loss = 1.8692)\n",
            "Saving model (epoch =  172,loss = 1.8390)\n",
            "Saving model (epoch =  177,loss = 1.7596)\n",
            "Saving model (epoch =  180,loss = 1.7504)\n",
            "Saving model (epoch =  184,loss = 1.7143)\n",
            "Saving model (epoch =  185,loss = 1.6983)\n",
            "Saving model (epoch =  186,loss = 1.6779)\n",
            "Saving model (epoch =  191,loss = 1.6714)\n",
            "Saving model (epoch =  194,loss = 1.6172)\n",
            "Saving model (epoch =  195,loss = 1.6079)\n",
            "Saving model (epoch =  196,loss = 1.6046)\n",
            "Saving model (epoch =  198,loss = 1.5971)\n",
            "Saving model (epoch =  199,loss = 1.5960)\n",
            "Saving model (epoch =  200,loss = 1.5735)\n",
            "Saving model (epoch =  203,loss = 1.5683)\n",
            "Saving model (epoch =  207,loss = 1.5516)\n",
            "Saving model (epoch =  210,loss = 1.5416)\n",
            "Saving model (epoch =  211,loss = 1.5344)\n",
            "Saving model (epoch =  215,loss = 1.5271)\n",
            "Saving model (epoch =  217,loss = 1.5059)\n",
            "Saving model (epoch =  218,loss = 1.4810)\n",
            "Saving model (epoch =  219,loss = 1.4810)\n",
            "Saving model (epoch =  220,loss = 1.4756)\n",
            "Saving model (epoch =  226,loss = 1.4642)\n",
            "Saving model (epoch =  230,loss = 1.4518)\n",
            "Saving model (epoch =  235,loss = 1.4273)\n",
            "Saving model (epoch =  239,loss = 1.4238)\n",
            "Saving model (epoch =  243,loss = 1.4036)\n",
            "Saving model (epoch =  244,loss = 1.3775)\n",
            "Saving model (epoch =  246,loss = 1.3718)\n",
            "Saving model (epoch =  256,loss = 1.3371)\n",
            "Saving model (epoch =  261,loss = 1.3288)\n",
            "Saving model (epoch =  269,loss = 1.3121)\n",
            "Saving model (epoch =  274,loss = 1.3103)\n",
            "Saving model (epoch =  275,loss = 1.2811)\n",
            "Saving model (epoch =  277,loss = 1.2778)\n",
            "Saving model (epoch =  279,loss = 1.2622)\n",
            "Saving model (epoch =  289,loss = 1.2574)\n",
            "Saving model (epoch =  301,loss = 1.2334)\n",
            "Saving model (epoch =  305,loss = 1.2203)\n",
            "Saving model (epoch =  313,loss = 1.2042)\n",
            "Saving model (epoch =  320,loss = 1.1983)\n",
            "Saving model (epoch =  330,loss = 1.1936)\n",
            "Saving model (epoch =  337,loss = 1.1851)\n",
            "Saving model (epoch =  341,loss = 1.1725)\n",
            "Saving model (epoch =  356,loss = 1.1666)\n",
            "Saving model (epoch =  360,loss = 1.1620)\n",
            "Saving model (epoch =  364,loss = 1.1544)\n",
            "Saving model (epoch =  372,loss = 1.1535)\n",
            "Saving model (epoch =  375,loss = 1.1504)\n",
            "Saving model (epoch =  378,loss = 1.1499)\n",
            "Saving model (epoch =  379,loss = 1.1419)\n",
            "Saving model (epoch =  391,loss = 1.1379)\n",
            "Saving model (epoch =  394,loss = 1.1312)\n",
            "Saving model (epoch =  403,loss = 1.1288)\n",
            "Saving model (epoch =  416,loss = 1.1249)\n",
            "Saving model (epoch =  417,loss = 1.1210)\n",
            "Saving model (epoch =  430,loss = 1.1058)\n",
            "Saving model (epoch =  439,loss = 1.1019)\n",
            "Saving model (epoch =  453,loss = 1.1015)\n",
            "Saving model (epoch =  456,loss = 1.0973)\n",
            "Saving model (epoch =  462,loss = 1.0962)\n",
            "Saving model (epoch =  469,loss = 1.0934)\n",
            "Saving model (epoch =  475,loss = 1.0912)\n",
            "Saving model (epoch =  477,loss = 1.0910)\n",
            "Saving model (epoch =  483,loss = 1.0809)\n",
            "Saving model (epoch =  487,loss = 1.0766)\n",
            "Saving model (epoch =  492,loss = 1.0743)\n",
            "Saving model (epoch =  497,loss = 1.0697)\n",
            "Saving model (epoch =  515,loss = 1.0694)\n",
            "Saving model (epoch =  517,loss = 1.0633)\n",
            "Saving model (epoch =  518,loss = 1.0551)\n",
            "Saving model (epoch =  551,loss = 1.0548)\n",
            "Saving model (epoch =  557,loss = 1.0542)\n",
            "Saving model (epoch =  564,loss = 1.0484)\n",
            "Saving model (epoch =  570,loss = 1.0468)\n",
            "Saving model (epoch =  580,loss = 1.0443)\n",
            "Saving model (epoch =  595,loss = 1.0422)\n",
            "Saving model (epoch =  596,loss = 1.0346)\n",
            "Saving model (epoch =  627,loss = 1.0275)\n",
            "Saving model (epoch =  629,loss = 1.0241)\n",
            "Saving model (epoch =  660,loss = 1.0227)\n",
            "Saving model (epoch =  676,loss = 1.0179)\n",
            "Saving model (epoch =  697,loss = 1.0160)\n",
            "Saving model (epoch =  702,loss = 1.0156)\n",
            "Saving model (epoch =  703,loss = 1.0137)\n",
            "Saving model (epoch =  704,loss = 1.0090)\n",
            "Saving model (epoch =  720,loss = 1.0065)\n",
            "Saving model (epoch =  721,loss = 1.0019)\n",
            "Saving model (epoch =  732,loss = 1.0018)\n",
            "Saving model (epoch =  777,loss = 0.9980)\n",
            "Saving model (epoch =  783,loss = 0.9963)\n",
            "Saving model (epoch =  858,loss = 0.9962)\n",
            "Saving model (epoch =  860,loss = 0.9923)\n",
            "Saving model (epoch =  880,loss = 0.9893)\n",
            "Saving model (epoch =  931,loss = 0.9860)\n",
            "Saving model (epoch =  953,loss = 0.9853)\n",
            "Saving model (epoch =  955,loss = 0.9845)\n",
            "Saving model (epoch =  961,loss = 0.9804)\n",
            "Saving model (epoch = 1018,loss = 0.9795)\n",
            "Saving model (epoch = 1216,loss = 0.9795)\n",
            "Saving model (epoch = 1231,loss = 0.9771)\n",
            "training set accuracy:0.267166319931399\n",
            "dev set accuracy:0.9771356582641602\n",
            "Finished training after 1732 epoches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G1izsmo-fv6"
      },
      "source": [
        "# 画图"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "v8Lnw1T9-iQK",
        "outputId": "8c25cda9-c7db-4b78-eb0c-20e2f6786752"
      },
      "source": [
        "'''训练过程中，训练集和验证集精度变化曲线'''\n",
        "def plot_learning_curve(loss_record,title=''):\n",
        "  x_1 = range(len(loss_record['train']))    #训练集数据的横坐标\n",
        "  x_2 = x_1[::len(loss_record['train']) // len(loss_record['dev'])]   #验证集数据的横坐标\n",
        "  figure(figsize=[6,4])     #图的大小\n",
        "\n",
        "  plt.plot(x_1,loss_record['train'],c='tab:red',label='train')    #训练集精度曲线\n",
        "  plt.plot(x_2,loss_record['dev'],c='tab:cyan',label='dev')     #验证集精度曲线\n",
        "\n",
        "  #画出图的其它次要部件\n",
        "  plt.ylim(0.0,5.)    #确定坐标上下限\n",
        "  plt.xlabel('testing steps')\n",
        "  plt.ylabel('MSE Loss')\n",
        "  plt.title('Learning curve of {}'.format(title))\n",
        "  plt.legend(['train','dev'])   #画出图例\n",
        "  plt.show()\n",
        "\n",
        "#画图\n",
        "plot_learning_curve(model_loss_record,title='deep model')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSEw7G2EEn6v"
      },
      "source": [
        "# 预测结果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khqEnkO7ErwB"
      },
      "source": [
        "preds = test(tt_set, model, device)  # predict COVID-19 cases with your model\n",
        "with open('preds.csv','w') as fp:\n",
        "  writer = csv.writer(fp)\n",
        "  writer.writerow(['id','tested_positive'])\n",
        "  for i in range(preds.shape[0]):\n",
        "    writer.writerow([i,preds[i]])"
      ],
      "execution_count": 41,
      "outputs": []
    }
  ]
}